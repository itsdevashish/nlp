{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Name :- Devashish Mayur Potnis\n",
        "#Roll No :- 43557\n",
        "#Practical No :- 4"
      ],
      "metadata": {
        "id": "kxV8lE__EJoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "CFJpWxrrEdSi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "\n",
        "        self.query = nn.Linear(d_model, d_model)\n",
        "        self.key = nn.Linear(d_model, d_model)\n",
        "        self.value = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, mask):\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # Linear transformations\n",
        "        Q = self.query(query)\n",
        "        K = self.key(key)\n",
        "        V = self.value(value)\n",
        "\n",
        "        # Split into heads\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, float('-1e20'))\n",
        "\n",
        "        attention = torch.nn.functional.softmax(energy, dim=-1)\n",
        "        x = torch.matmul(attention, V)\n",
        "\n",
        "        # Reshape and concatenate\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        x = x.view(batch_size, -1, self.d_model)\n",
        "\n",
        "        # Final linear layer\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, ff_dim, dropout=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model, n_heads)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(d_model, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, d_model)\n",
        "        )\n",
        "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
        "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Self-attention\n",
        "        attention = self.self_attention(x, x, x, mask)\n",
        "        x = x + self.dropout(attention)\n",
        "        x = self.layer_norm1(x)\n",
        "\n",
        "        # Feedforward\n",
        "        ffn_output = self.ffn(x)\n",
        "        x = x + self.dropout(ffn_output)\n",
        "        x = self.layer_norm2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, ff_dim, n_layers, max_seq_length, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(d_model, n_heads, ff_dim, dropout)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.position_embedding = nn.Embedding(max_seq_length, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        positions = torch.arange(0, x.size(1)).expand(x.size(0), x.size(1)).to(self.device)\n",
        "        x = x + self.position_embedding(positions)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "d_model = 512\n",
        "n_heads = 8\n",
        "ff_dim = 2048\n",
        "n_layers = 6\n",
        "max_seq_length = 100\n",
        "dropout = 0.1\n",
        "\n",
        "# Create transformer encoder\n",
        "transformer_encoder = TransformerEncoder(d_model, n_heads, ff_dim, n_layers, max_seq_length, dropout)\n",
        "\n",
        "# Dummy input\n",
        "input_data = torch.rand((16, 100, d_model))\n",
        "\n",
        "# Mask for padding\n",
        "padding_mask = (input_data.sum(dim=-1) != 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "# Forward pass\n",
        "output_data = transformer_encoder(input_data, padding_mask)\n",
        "print(output_data)\n",
        "print(\"Output shape:\", output_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj2FY_aPEf8w",
        "outputId": "9fd5d837-72c1-44a7-db93-7d1d72ba6618"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 2.1190, -0.3070,  0.8684,  ..., -0.5964,  2.0397, -0.1870],\n",
            "         [-0.1040,  0.7411,  0.3018,  ...,  0.3549,  0.9209,  1.1006],\n",
            "         [-0.0560, -0.0112, -0.6999,  ..., -1.7957,  1.8597,  1.1984],\n",
            "         ...,\n",
            "         [-0.8701,  0.4968,  0.5823,  ...,  1.4080,  0.4889, -0.0852],\n",
            "         [ 0.1658,  1.8266,  0.4646,  ...,  0.9672,  2.0625,  0.5057],\n",
            "         [ 2.1088, -0.4424, -0.1533,  ..., -1.7459,  1.5994,  0.2504]],\n",
            "\n",
            "        [[ 1.7615, -0.2889, -0.3891,  ..., -0.1173,  2.2502,  0.6596],\n",
            "         [-0.0801,  0.9621,  1.0993,  ...,  0.2810,  0.4042,  1.0537],\n",
            "         [-0.2148, -0.4786, -0.8580,  ..., -1.7894,  0.3084,  1.9672],\n",
            "         ...,\n",
            "         [-0.1644,  0.1798,  0.6835,  ...,  1.9033,  0.4577, -0.2276],\n",
            "         [ 0.4457,  1.8287,  0.3376,  ...,  1.2803,  1.7753,  0.1414],\n",
            "         [ 1.3813, -0.1967,  0.3527,  ..., -2.0245,  1.8690,  0.7219]],\n",
            "\n",
            "        [[ 1.5487,  0.4550, -0.3476,  ...,  0.5577, -0.2677,  0.4746],\n",
            "         [-0.2533,  1.2018, -0.3337,  ...,  1.3087, -0.3117,  1.8456],\n",
            "         [ 0.0392,  0.2372, -0.7243,  ..., -1.5301,  1.4975, -0.1887],\n",
            "         ...,\n",
            "         [-1.0118,  0.3466,  0.8376,  ...,  1.0761, -0.1112, -0.1456],\n",
            "         [ 0.1799,  2.1484,  0.7163,  ...,  0.8196,  0.9949,  0.2348],\n",
            "         [ 1.7826, -0.7706, -0.1414,  ..., -1.6288,  1.1455, -0.1362]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.6773,  0.1421,  0.1515,  ...,  0.0792, -0.2927,  0.7043],\n",
            "         [-0.2099,  0.5972,  1.2818,  ..., -0.0620,  0.3339,  1.4662],\n",
            "         [ 0.6037,  0.2695, -1.7842,  ..., -2.1199,  1.7564,  1.6681],\n",
            "         ...,\n",
            "         [-0.2805,  0.9082,  0.5237,  ...,  0.9944, -0.1464,  0.1758],\n",
            "         [ 0.6408,  1.4597,  0.8561,  ...,  0.9668,  1.4864,  0.7215],\n",
            "         [ 0.4464, -0.5181, -0.3322,  ..., -1.7193,  1.8078,  0.0995]],\n",
            "\n",
            "        [[ 2.5319, -0.6074, -0.1290,  ...,  0.5560,  2.1452,  0.3993],\n",
            "         [ 0.4788,  0.1200,  0.6945,  ...,  1.0783,  0.3872,  1.6319],\n",
            "         [-0.0958, -0.0688, -1.0145,  ..., -1.5131,  1.9654,  1.8063],\n",
            "         ...,\n",
            "         [-0.0800,  0.5460,  1.0979,  ...,  1.5248, -0.0138,  0.0037],\n",
            "         [ 0.3993,  1.8163,  0.7265,  ...,  1.0724,  1.3743,  0.5054],\n",
            "         [ 1.7418, -0.7833, -0.4859,  ..., -1.6429,  0.3648, -0.5290]],\n",
            "\n",
            "        [[ 2.4711, -0.0365,  0.0189,  ...,  0.7976,  2.4153,  0.3994],\n",
            "         [-0.4373,  0.7882,  0.3062,  ...,  0.6766,  1.0299,  1.1360],\n",
            "         [-0.3823, -0.6532, -0.9445,  ..., -1.4495,  2.0618,  1.2039],\n",
            "         ...,\n",
            "         [-0.1334,  0.4338,  0.7388,  ...,  1.1025,  0.4610, -0.6842],\n",
            "         [ 0.1409,  1.2616, -0.0734,  ...,  0.0716,  1.4038, -0.1437],\n",
            "         [ 2.1019, -0.5420,  0.1469,  ..., -1.4499,  1.3669, -0.3051]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "Output shape: torch.Size([16, 100, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "09Oa7n2mEgAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}